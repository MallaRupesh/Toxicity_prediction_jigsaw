{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "048e309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# Utils\n",
    "import pickle\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61bbdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_func_1(x):\n",
    "    \n",
    "    '''Final function 1 handling all the cleaning and loading of tokenizer , vectorizer and model and predicting '''\n",
    "    #Using regex and string manipulation to clean the data \n",
    "\n",
    "\n",
    "    def clean(data):\n",
    "        #https://www.kaggle.com/andrej0marinchenko/jigsaw-ensemble-0-86/notebook\n",
    "        data = data.str.replace('https?://\\S+|www\\.\\S+', ' social medium ')      \n",
    "\n",
    "        data = data.str.lower()\n",
    "        data = data.str.replace(\"4\", \"a\") \n",
    "        data = data.str.replace(\"2\", \"l\")\n",
    "        data = data.str.replace(\"5\", \"s\") \n",
    "        data = data.str.replace(\"1\", \"i\") \n",
    "        data = data.str.replace(\"!\", \"i\") \n",
    "        data = data.str.replace(\"|\", \"i\") \n",
    "        data = data.str.replace(\"0\", \"o\") \n",
    "        data = data.str.replace(\"8\", \"ate\") \n",
    "        data = data.str.replace(\"3\", \"e\") \n",
    "        data = data.str.replace(\"9\", \"g\")\n",
    "        data = data.str.replace(\"6\", \"g\")\n",
    "        data = data.str.replace(\"@\", \"a\")\n",
    "        data = data.str.replace(\"$\", \"s\")\n",
    "        data = data.str.replace(\"l3\", \"b\") \n",
    "        data = data.str.replace(\"7\", \"t\") \n",
    "        data = data.str.replace(\"7\", \"+\") \n",
    "\n",
    "        data = data.str.replace(\"#ofc\", \" of fuckin course \")\n",
    "        data = data.str.replace(\"fggt\", \" faggot \")\n",
    "        data = data.str.replace(\"your\", \" your \")\n",
    "        data = data.str.replace(\"self\", \" self \")\n",
    "        data = data.str.replace(\"cuntbag\", \" cunt bag \")\n",
    "        data = data.str.replace(\"fartchina\", \" fart china \")    \n",
    "        data = data.str.replace(\"youi\", \" you i \")\n",
    "        data = data.str.replace(\"cunti\", \" cunt i \")\n",
    "        data = data.str.replace(\"sucki\", \" suck i \")\n",
    "        data = data.str.replace(\"pagedelete\", \" page delete \")\n",
    "        data = data.str.replace(\"cuntsi\", \" cuntsi \")\n",
    "        data = data.str.replace(\"i'm\", \" i am \")\n",
    "        data = data.str.replace(\"offuck\", \" of fuck \")\n",
    "        data = data.str.replace(\"centraliststupid\", \" central ist stupid \")\n",
    "        data = data.str.replace(\"hitleri\", \" hitler i \")\n",
    "        data = data.str.replace(\"i've\", \" i have \")\n",
    "        data = data.str.replace(\"i'll\", \" sick \")\n",
    "        data = data.str.replace(\"fuck\", \" fuck \")\n",
    "        data = data.str.replace(\"f u c k\", \" fuck \")\n",
    "        data = data.str.replace(\"shit\", \" shit \")\n",
    "        data = data.str.replace(\"bunksteve\", \" bunk steve \")\n",
    "        data = data.str.replace('wikipedia', ' social medium ')\n",
    "        data = data.str.replace(\"faggot\", \" faggot \")\n",
    "        data = data.str.replace(\"delanoy\", \" delanoy \")\n",
    "        data = data.str.replace(\"jewish\", \" jewish \")\n",
    "        data = data.str.replace(\"sexsex\", \" sex \")\n",
    "        data = data.str.replace(\"allii\", \" all ii \")\n",
    "        data = data.str.replace(\"i'd\", \" i had \")\n",
    "        data = data.str.replace(\"'s\", \" is \")\n",
    "        data = data.str.replace(\"youbollocks\", \" you bollocks \")\n",
    "        data = data.str.replace(\"dick\", \" dick \")\n",
    "        data = data.str.replace(\"cuntsi\", \" cuntsi \")\n",
    "        data = data.str.replace(\"mothjer\", \" mother \")\n",
    "        data = data.str.replace(\"cuntfranks\", \" cunt \")\n",
    "        data = data.str.replace(\"ullmann\", \" jewish \")\n",
    "        data = data.str.replace(\"mr.\", \" mister \")\n",
    "        data = data.str.replace(\"aidsaids\", \" aids \")\n",
    "        data = data.str.replace(\"njgw\", \" nigger \")\n",
    "        data = data.str.replace(\"wiki\", \" social medium \")\n",
    "        data = data.str.replace(\"administrator\", \" admin \")\n",
    "        data = data.str.replace(\"gamaliel\", \" jewish \")\n",
    "        data = data.str.replace(\"rvv\", \" vanadalism \")\n",
    "        data = data.str.replace(\"admins\", \" admin \")\n",
    "        data = data.str.replace(\"pensnsnniensnsn\", \" penis \")\n",
    "        data = data.str.replace(\"pneis\", \" penis \")\n",
    "        data = data.str.replace(\"pennnis\", \" penis \")\n",
    "        data = data.str.replace(\"pov.\", \" point of view \")\n",
    "        data = data.str.replace(\"vandalising\", \" vandalism \")\n",
    "        data = data.str.replace(\"cock\", \" dick \")\n",
    "        data = data.str.replace(\"asshole\", \" asshole \")\n",
    "        data = data.str.replace(\"youi\", \" you \")\n",
    "        data = data.str.replace(\"afd\", \" all fucking day \")\n",
    "        data = data.str.replace(\"sockpuppets\", \" sockpuppetry \")\n",
    "        data = data.str.replace(\"iiprick\", \" iprick \")\n",
    "        data = data.str.replace(\"penisi\", \" penis \")\n",
    "        data = data.str.replace(\"warrior\", \" warrior \")\n",
    "        data = data.str.replace(\"loil\", \" laughing out insanely loud \")\n",
    "        data = data.str.replace(\"vandalise\", \" vanadalism \")\n",
    "        data = data.str.replace(\"helli\", \" helli \")\n",
    "        data = data.str.replace(\"lunchablesi\", \" lunchablesi \")\n",
    "        data = data.str.replace(\"special\", \" special \")\n",
    "        data = data.str.replace(\"ilol\", \" i lol \")\n",
    "        data = data.str.replace(r'\\b[uU]\\b', 'you')\n",
    "        data = data.str.replace(r\"what's\", \"what is \")\n",
    "        data = data.str.replace(r\"\\'s\", \" is \")\n",
    "        data = data.str.replace(r\"\\'ve\", \" have \")\n",
    "        data = data.str.replace(r\"can't\", \"cannot \")\n",
    "        data = data.str.replace(r\"n't\", \" not \")\n",
    "        data = data.str.replace(r\"i'm\", \"i am \")\n",
    "        data = data.str.replace(r\"\\'re\", \" are \")\n",
    "        data = data.str.replace(r\"\\'d\", \" would \")\n",
    "        data = data.str.replace(r\"\\'ll\", \" will \")\n",
    "        data = data.str.replace(r\"\\'scuse\", \" excuse \")\n",
    "        data = data.str.replace('\\s+', ' ')  \n",
    "        data = data.str.replace(r'(.)\\1+', r'\\1\\1') \n",
    "        data = data.str.replace(\"[:|♣|'|§|♠|*|/|?|=|%|&|-|#|•|~|^|>|<|►|_]\", '')\n",
    "\n",
    "\n",
    "        data = data.str.replace(r\"what's\", \"what is \")    \n",
    "        data = data.str.replace(r\"\\'ve\", \" have \")\n",
    "        data = data.str.replace(r\"can't\", \"cannot \")\n",
    "        data = data.str.replace(r\"n't\", \" not \")\n",
    "        data = data.str.replace(r\"i'm\", \"i am \")\n",
    "        data = data.str.replace(r\"\\'re\", \" are \")\n",
    "        data = data.str.replace(r\"\\'d\", \" would \")\n",
    "        data = data.str.replace(r\"\\'ll\", \" will \")\n",
    "        data = data.str.replace(r\"\\'scuse\", \" excuse \")\n",
    "        data = data.str.replace(r\"\\'s\", \" \")\n",
    "\n",
    "        # Clean some punctutations\n",
    "        data = data.str.replace('\\n', ' \\n ')\n",
    "        data = data.str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n",
    "        # Replace repeating characters more than 3 times to length of 3\n",
    "        data = data.str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')   \n",
    "        # Add space around repeating characters\n",
    "        data = data.str.replace(r'([*!?\\']+)',r' \\1 ')    \n",
    "        # patterns with repeating characters \n",
    "        data = data.str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n",
    "        data = data.str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n",
    "        data = data.str.replace(r'[ ]{2,}',' ').str.strip()   \n",
    "        data = data.str.replace(r'[ ]{2,}',' ').str.strip()   \n",
    "        data = data.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "        return data\n",
    "\n",
    "    \n",
    "    # Loading the pre trained bert tokenizer \n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    def dummy_fun(doc):\n",
    "        return doc\n",
    "    # Loading the pre trained tfidf vectorizer\n",
    "    with open('tfidf.pickle', 'rb') as handle:\n",
    "        vectorizer = pickle.load(handle)\n",
    "\n",
    "    # Loading the model\n",
    "    regressor = pickle.load(open(\"/Users/rupesh/Downloads/Toxicity /finalized_model.sav\", 'rb'))\n",
    "\n",
    "\n",
    "    # cleaning the text \n",
    "#     x = clean(x,'text')\n",
    "\n",
    "    tokenized_comments = tokenizer(x.tolist())['input_ids']\n",
    "\n",
    "    comments_tr = vectorizer.transform(tokenized_comments)\n",
    "\n",
    "    preds = regressor.predict(comments_tr)\n",
    "\n",
    "    \n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df536a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_DATA_PATH = \"/Users/rupesh/Downloads/Toxicity /jigsaw-toxic-severity-rating/validation_data.csv\"\n",
    "\n",
    "TEST_DATA_PATH = \"/Users/rupesh/Downloads/Toxicity /jigsaw-toxic-severity-rating/comments_to_score.csv\"\n",
    "cts=pd.read_csv(TEST_DATA_PATH)\n",
    "df_valid2=pd.read_csv(VALID_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df3239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_func_1(df_valid2['more_toxic'])\n",
    "# predictions for more toxic comments (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5774e8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06340012, 0.03892182, 0.02588923, ..., 0.02964314, 0.02964314,\n",
       "       0.02964314])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_func_1(df_valid2['less_toxic'])\n",
    "# predictions for less toxic comments (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5cd76aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00150592,  0.05740913, -0.00339071, ..., -0.00790545,\n",
       "        0.05248892,  0.02962038])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_func_1(cts['text'])\n",
    "# predictions for comments to score for kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "67a1022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this kaggle problem the majority of the results of the results are averaged and ranked so there is no official metrics and in many kernels they have used simple metrics like accuracy , MAE , etc \n",
    "def final_func_2(X,y):\n",
    "    \n",
    "    preds=final_func_1(df_valid2['more_toxic'])\n",
    "    score =mean_absolute_error(y, preds)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aeb0c4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8687723665562712"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_func_2(df_valid2['more_toxic'] , [1] * len(df_valid2['more_toxic']))\n",
    "# As we declared 1 as more toxic in modelling so we are comparing them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bf7af632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13284049630784242"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_func_2(df_valid2['less_toxic'] , [0] * len(df_valid2['less_toxic']))\n",
    "# As we declared 0 as less toxic in modelling so we are comparing them "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
